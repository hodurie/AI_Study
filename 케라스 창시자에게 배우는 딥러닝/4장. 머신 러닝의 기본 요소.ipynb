{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4장. 머신 러닝의 기본 요소.ipynb","provenance":[],"collapsed_sections":["nPzL7PeB6zHX","pkC_dNSK6zKu","HsoKJguJPmjG"],"authorship_tag":"ABX9TyOdmROJbKrM6f6MSJn+iweM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"obN-YZic6zEl"},"source":["# 4장. 머신 러닝의 기본 요소\n","## 4.1 머신 러닝의 네 가지 분류\n","### 지도 학습\n","**훈련 데이터의 입력과 타깃 사이의 있는 관계를 학습하는 것**  \n","\n","일반적으로 분류와 회귀로 구성  \n","\n","일반적이지 않은 형태  \n","- 시퀀스 생성 : 사진을 설명하는 캡션을 생성\n","- 구문 트리 : 문장이 주어지면 분해된 구문 트리 예측\n","- 물체 감지 : 사진 안 특정 물체 주위에 경계 상자 그리기\n","- 이미지 분할 : 사진 안 특정 물체에 마스킹\n"," \n","### 비지도 학습\n","**어떤 타깃도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾는 것**  \n","- 지도 학습 문제를 풀기 전 데이터셋을 잘 이해하기 위해 필수적으로 거치는 단계\n","\n","일반적인 범주\n","- 차원 축소\n","- 군집\n","\n","### 자기 지도 학습\n","**학습 과정에서 사람이 개입하지 않는 지도 학습**  \n","\n","### 강화 학습\n","**환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습** \n","\n"]},{"cell_type":"markdown","metadata":{"id":"nPzL7PeB6zHX"},"source":["## 4.2 머신 러닝 모델 평가\n","머신 러닝의 목표\n","- 일반화된 모델을 얻는 것\n","\n","### 훈련, 검증, 테스트 세트\n","모델 평가의 핵심\n","- 가용된 데이터를 훈련, 검증, 테스트 3개의 세트로 나누는 것\n","\n","1. 훈련 세트에서 모델을 훈련\n","2. 검증 세트에서 모델을 평가\n","3. 테스트 세트에서 최종적으로 모델 테스트\n","\n","세 개의 세트로 나누는 이유\n","- 테스트 세트의 정보 누설 방지로 일반화 성능 높이기 위해\n"," > 정보 누설이란, 검증 데이터에 관한 정보가 모델로 새는 것\n","\n","데이터가 적을 때 세 개의 세트로 나누는 방법\n","1. 단순 홀드아웃 검증\n","2. K-겹 교차 검증\n","3. 셔플링을 사용한 반복 K-겹 교차 검증\n","\n","#### 단순 홀드아웃 검증\n","1. 데이터의 일정량을 테스트 세트로 떼어 놓음\n","2. 남은 데이터에서 훈련하고 테스트 세트로 평가\n","\n","단점\n","- 샘플 수가 적어 현 데이터가 전체 데이터를 대표할 수 없음\n","\n","\n","\n","\n"," "]},{"cell_type":"markdown","metadata":{"id":"pkC_dNSK6zKu"},"source":["#### K-겹 교차 검증\n","1. 데이터를 동일한 크기로 K개로 나눔\n","2. 각 분할 i에 대해 남은 K-1개의 분할로 모델을 훈련\n","3. 분할 i는 모델을 평가\n","4. K개의 값들의 평균으로 최종 점수 도출\n","\n","모델의 성능이 데이터 분할에 따라 편차가 클 때 사용\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WXQtrH7i6zNf"},"source":["\n","#### 셔플링을 사용한 반복 K-겹 교차 검증\n","1. K-겹 교차 검증을 여러 번 적용\n","> K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞음\n","2. 모든 K-겹 교차 검증 값을 평균내 최종 점수 도출"]},{"cell_type":"markdown","metadata":{"id":"obiCeo-M6zRb"},"source":["### 기억해야 할 것\n","- 대표성 있는 데이터 : 훈련 세트와 테스트 세트가 주어진 데이터에 대한 대표성이 있어야 함\n","- 시간의 방향 : 과거로부터 미래를 예측하려고 한다면 테스트 세트의 모든 데이터는 훈련 세트의 데이터보다 미래여야 함\n","- 데이터 중복 : 훈련 세트와 검증 세트가 중복되지 않게 해야 함"]},{"cell_type":"markdown","metadata":{"id":"HsoKJguJPmjG"},"source":["## 4.3 데이터 전처리, 특성 공학, 특성 학습\n","### 신경망을 위한 데이터 전처리\n","데이터 전처리 목적\n","- 원본 데이터를 신경망에 적용하기 쉽게 만드는 것\n","\n","데이터 전처리 방법\n","- 벡터화\n","- 정규화\n","- 누락된 값 다루기\n","- 특성 추출\n","\n","#### 벡터화\n","**부동 소수로 이루어진 텐서로 만드는 작업**  \n","\n","신경망의 입력과 타깃은 부동 소수로 이루어진 텐서  \n","- 데이터 벡터화\n","\n","#### 값 정규화\n","**각 특성을 평균 0 표준 편차 1로 만드는 작업**   \n","\n","네트워크를 쉽게 학습시키기 위한 작업\n","- 0과 1 사이의 작은 값을 취해야 함\n","- 데이터 값들이 비슷한 범위를 가져야 함\n","\n","#### 누락된 값 다루기\n","누락 된 값을 확인해 제거 하거나, 0, 평균, 중간 값 등으로 채워 넣기\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wsTTAdswhGth"},"source":["### 특성공학\n","**데이터와 머신 러닝 알고리즘에 관한 지식을 사용하는 단계**  \n","\n","특성 공학이 필요한 이유\n","- 적은 자원을 사용하여 문제를 풂\n","- 적은 데이터로 문제를 풀 수 있음"]},{"cell_type":"markdown","metadata":{"id":"jQH_q4bQiHpL"},"source":["## 4.4 과대적합과 과소적합\n","### 과대적합\n","**모델이 훈련 데이터에 최적화 돼 일반화가 어려움**  \n","- 훈련 데이터를 여러 번 반복 학습\n","- 검증 세트의 성능이 멈추고 감소하기 시작\n"," > 훈련 데이터에 특화된 패턴을 학습  \n"," \n","#### 과대적합 줄이는 방법\n","1. 많은 훈련 데이터 모으기\n","2. 모델이 수용할 수 있는 정보량을 조절하거나 저장할 수 있는 정보에 제약 가하기\n","\n","### 과소적합\n","**모델이 훈련 데이터의 특성을 모두 학습하지 못한 경우**  \n","\n","### 최적화\n","- 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정\n","\n","### 일반화\n","- 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는 지\n","\n","### 네트워크 크기 축소\n","과대적합을 줄이는 가장 단순한 방법\n","- 모델의 크기  줄이기\n"," > 모델에 있는 학습 파라미터의 수 줄이기\n","\n","### 가중치 규제 추가\n","\n","**오캄의 면도날**  \n","- 어떤 것에 두 가지의 설명이 있다면 더 적은 가정이 필요한 간단한 설명이 옳은 것이라는 이론\n","\n","신경망 모델에도 적용되는 이론\n","- 복잡한 모델이 과적합될 가능성이 높음\n"," > 간단한 모델, 파라미터 값 분포의 엔트로피가 작은 모델\n","\n","가중치 분포를 균일하게 하는 방법  \n","**가중치 규제**  \n","- L1 규제 : 가중치의 절대값에 비례하는 비용 추가 (가중치의 L1 노름)\n","- L2 규제 : 가중치의 제곱에 비례하는 비용 추가, **가중치 감쇠**라고도 부름 (가중치의 L2 노름)\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"i_4GFWFBayHz","executionInfo":{"status":"ok","timestamp":1607583492268,"user_tz":-540,"elapsed":3147,"user":{"displayName":"Ho","photoUrl":"","userId":"04796031619100753677"}}},"source":["# 케라스에서 사용할 수 있는 가중치 규제\r\n","from keras import regularizers\r\n","\r\n","regularizers.l1(0.001)\r\n","regularizers.l2(0.001)\r\n","regularizers.l1_l2(l1 = 0.001, l2 = 0.001)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IaknOOcbcFhv"},"source":["페널티 항은 훈련할 때만 추가\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"mVgdq4BWcNwX"},"source":["### 드롭아웃 추가\r\n","\r\n","**네트워크 층에 적용하면 훈련 동안 무작위로 층의 일부 출력 특성을 제외시킴**\r\n","- 드롭 아웃 적용시 벡터의 일부가 무작위로 0으로 변환 됨\r\n","- 일반적으로 0.2 ~ 0.5 사이로 적용\r\n"," > 비율은 0이 될 특성의 비율\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"gOjTdAfvdXe1"},"source":["# 훈련 시\r\n","layer_output *= np.random.randint(0, high = 2, size = layer_output.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nA69dnijPPF"},"source":["테스트 할 때는 드롭아웃 비율로 출력을 낮춰야 함"]},{"cell_type":"code","metadata":{"id":"hK_-KoRMjD9o"},"source":["# 테스트 시\r\n","layer_output *= 0.5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NExjBkJ1jNR9"},"source":["층의 출력 값에 노이즈를 추가하여 중요하지 않은 우연한 패턴을 깨뜨리는 작업"]},{"cell_type":"markdown","metadata":{"id":"KitiklZvjns2"},"source":["## 4.5 보편적인 머신 러닝 작업 흐름\r\n","### 문제 정의와 데이터셋 수집\r\n","\r\n","문제 정의\r\n","- 입력 데이터 정보, 예측 정보, 가용한 훈련 데이터 유무\r\n","- 분류(이진/다중), 회귀(스칼라/벡터), 비지도 학습, 강화 학습 \r\n","\r\n","문제에 대한 가설\r\n","- '주어진 입력으로 출력을 예측 할 수 있다'는 가설\r\n","- '가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다'는 가설\r\n","\r\n","가설은 가설일 뿐 검증 과정을 거쳐야 한다.  \r\n","하지만, 가설 검증이 될지 안 될지 모름\r\n","> 모든 문제가 해결책을 제시해 주지 않음\r\n","\r\n","### 성공 지표 선택\r\n","\r\n","클래스 분포가 균일 : 정확도, ROC, AUC  \r\n","클래스 분포가 불균일 : 정밀도, 재현율  \r\n","랭킹 문제, 다중 레이블 문제 : 평균 정밀도  \r\n","\r\n","문제가 무엇인지에 따라 지표를 달리해야함\r\n","\r\n","### 평가 방법 선택\r\n","\r\n","목표 설정 후 진척 상황 평가\r\n","- 홀드아웃 검증 세트 분리\r\n","- K-겹 교차 검증\r\n","- 반복 K-겹 교차 검증\r\n","\r\n","### 데이터 준비\r\n","\r\n","머신 러닝에 주입 할 데이터\r\n","- 텐서 데이터\r\n","- 범위가 다를 경우 정규화\r\n","- 특성 공학 수행, 특히 데이터가 적을 때 사용\r\n","\r\n","### 기본보다 나은 모델 훈련하기\r\n","\r\n","이 단계의 목표  \r\n","**통계적 검정력** 달성\r\n","> 단순한 모델보다 나은 수준의 작은 모델 개발\r\n","\r\n","여러개의 타당성 있는 네트워크 구조 적용  \r\n","하지만, 무작위로 예측하는 것보다 낫지 않을 수 있음  \r\n","- 입력 데이터에 존재하지 않은 값을 얻으려 하는 신호\r\n","- 위에 세운 가설이 잘못 됐을 수 있음\r\n","- 기획을 다시 진행\r\n","\r\n","통계적 검정력이 존재할 경우\r\n","- 마지막 층의 활성화 함수 : 네트워크의 출력에 필요한 제한 가함\r\n","- 손실 함수 : 문제 종류에 따라 적절히 적합\r\n","- 최족화 설정 : 옵티마이저, 학습률 등의 하이퍼파라미터 조정\r\n","\r\n","|문제유형|마지막 층의 활성화 함수|손실함수\r\n","|:------|:---|:---\r\n","|이진분류|시그모이드|binary_crossentropy\r\n","|단일 레이블 다중 분류|소프트 맥스|categorical_crossentropy\r\n","|다중 레이블 다중 분류|시그모이드|binary_crossentropy\r\n","|임의 값에 대한 회귀|없음|mse\r\n","|0과 1 사이 값에 대한 회귀|시그모이드|mse 또는 binary_crossentropy\r\n","\r\n","\r\n","### 몸집 키우기: 과대적합 모델 구축\r\n","이상적 모델을 찾기 위한 작업\r\n","- **과대 적합의 경계값 찾기**  \r\n","- 모델 규제와 하이퍼 파라미터 튜닝\r\n","\r\n","과대 적합 모델\r\n","- 층 추가\r\n","- 층 크기 키우기\r\n","- 많은 에포크로 훈련\r\n","\r\n","모니터링 방법\r\n","- 훈련 손실과 검증 손실\r\n","- 검증 데이터에서 모델 성능이 감소하기 시작할 때 과대적합\r\n","\r\n","### 모델 규제와 하이퍼파라미터 튜닝\r\n","\r\n","이상적 모델을 찾기 위한 작업\r\n","- 과대 적합의 경계값 찾기\r\n","- **모델 규제와 하이퍼 파라미터 튜닝**\r\n","\r\n","모델 규제와 하이퍼 파라미터 튜닝\r\n","- 드롭아웃 추가\r\n","- 층을 추가 또는 제거\r\n","- L1 또는 L2 적용\r\n","- L1, L2 모두 적용\r\n","- 선택적 특성 공학 적용\r\n"," > 새로운 특성 추가 또는 유용하지 않은 특성 제거"]},{"cell_type":"code","metadata":{"id":"wlcrDezYopzD"},"source":[""],"execution_count":null,"outputs":[]}]}