{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Xception.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPB2kP4sqAQmc+9pouNazpv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"wWmNeK5upQ3r","executionInfo":{"status":"ok","timestamp":1621408740658,"user_tz":-540,"elapsed":490,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":424,"outputs":[]},{"cell_type":"code","metadata":{"id":"FU2OPDV2wRl7","executionInfo":{"status":"ok","timestamp":1621408740971,"user_tz":-540,"elapsed":798,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class Xception(nn.Module):\n","    def __init__(self, in_channels=3, num_classes=10):\n","        super(Xception, self).__init__()\n","        self.entryflow = EntryFlow(in_channels)\n","        self.middleflow = MiddleFlow(728)\n","        self.exitflow = ExitFlow(728, num_classes)\n","\n","    def forward(self, x):\n","        x = self.entryflow(x)\n","        x = self.middleflow(x)\n","        x = self.exitflow(x)\n","        print(\"exitflow\")\n","        return x"],"execution_count":425,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbloG5fxwhQG","executionInfo":{"status":"ok","timestamp":1621408740971,"user_tz":-540,"elapsed":794,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class SeparableConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(SeparableConv, self).__init__()\n","        self.depthwiseConv = nn.Conv2d(in_channels, in_channels, 3, 1, 1, groups=in_channels, bias=False)\n","        self.bn1 = nn.BatchNorm2d(in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.pointwiseConv = nn.Conv2d(in_channels, out_channels, 1, 1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","\n","    def forward(self, x):\n","        x = self.relu(self.bn1(self.depthwiseConv(x)))\n","        x = self.relu(self.bn2(self.pointwiseConv(x)))\n","        return x"],"execution_count":426,"outputs":[]},{"cell_type":"code","metadata":{"id":"DrYMR9lzwsxC","executionInfo":{"status":"ok","timestamp":1621408740972,"user_tz":-540,"elapsed":793,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class StandardConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2):\n","        super(StandardConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, bias=False)\n","        self.bn = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","    \n","    def forward(self, x):       \n","        x = self.relu(self.bn(self.conv(x)))\n","        return x"],"execution_count":427,"outputs":[]},{"cell_type":"code","metadata":{"id":"RpvsIbjr-p8F","executionInfo":{"status":"ok","timestamp":1621408740972,"user_tz":-540,"elapsed":791,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, reps, first_relu=True, max_pool=False, skip=True):\n","        super(Block, self).__init__()\n","        self.skip = skip\n","        self.layers = self.make_layers(in_channels, out_channels, reps, first_relu, max_pool)\n","        self.skip_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, bias=False)\n","        self.skip_bn = nn.BatchNorm2d(out_channels)\n","\n","    def make_layers(self, in_channels, out_channels, reps, first_relu, max_pool):\n","        layers = []\n","\n","        if first_relu:\n","            layers.append(nn.ReLU(inplace=True))\n","        \n","        for rep in range(reps):\n","            if rep > 0:\n","                layers.append(nn.ReLU(inplace=True))\n","            layers.append(SeparableConv(in_channels, out_channels))\n","            in_channels = out_channels\n","\n","        if max_pool:\n","            layers.append(nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.layers(x)\n","        if self.skip:\n","            out += self.skip_bn(self.skip_conv(x))\n","        return out"],"execution_count":428,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsrkTTbVw3DL","executionInfo":{"status":"ok","timestamp":1621408741267,"user_tz":-540,"elapsed":1084,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class EntryFlow(nn.Module):\n","    def __init__(self, in_channels):\n","        super(EntryFlow, self).__init__()\n","        self.conv1 = StandardConv(in_channels, 32)\n","        self.conv2 = StandardConv(32, 64, stride=1)\n","\n","        self.block1 = Block(64, 128, 2, first_relu=False, max_pool=True)\n","        self.block2 = Block(128, 256, 2, max_pool=True)\n","        self.block3 = Block(256, 728, 2, max_pool=True)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.block1(x)\n","        x = self.block2(x)\n","        x = self.block3(x)\n","        return x"],"execution_count":429,"outputs":[]},{"cell_type":"code","metadata":{"id":"coqxa_bEHv2c","executionInfo":{"status":"ok","timestamp":1621408741268,"user_tz":-540,"elapsed":1083,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class MiddleFlow(nn.Module):\n","    def __init__(self, in_channels):\n","        super(MiddleFlow, self).__init__()\n","        self.block1 = Block(in_channels, in_channels, reps=3, skip=False)\n","        self.block2 = Block(in_channels, in_channels, reps=3, skip=False)\n","        self.block3 = Block(in_channels, in_channels, reps=3, skip=False)\n","        self.block4 = Block(in_channels, in_channels, reps=3, skip=False)\n","        self.block5 = Block(in_channels, in_channels, reps=3, skip=False)\n","        self.block6 = Block(in_channels, in_channels, reps=3, skip=False)\n","        self.block7 = Block(in_channels, in_channels, reps=3, skip=False)\n","        self.block8 = Block(in_channels, in_channels, reps=3, skip=False)\n","\n","    def forward(self, x):\n","        x = self.block1(x) + x\n","        x = self.block2(x) + x\n","        x = self.block3(x) + x\n","        x = self.block4(x) + x\n","        x = self.block5(x) + x\n","        x = self.block6(x) + x\n","        x = self.block7(x) + x\n","        x = self.block8(x) + x\n","        return x    "],"execution_count":430,"outputs":[]},{"cell_type":"code","metadata":{"id":"RB3TpbQLJP4i","executionInfo":{"status":"ok","timestamp":1621408741268,"user_tz":-540,"elapsed":1081,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class ExitFlow(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(ExitFlow, self).__init__()\n","        self.layers = nn.Sequential(\n","            nn.ReLU(inplace=True),\n","            SeparableConv(in_channels, in_channels),\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(inplace=True),\n","            SeparableConv(in_channels, 1024),\n","            nn.BatchNorm2d(1024),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        )\n","        self.skip_conv = nn.Conv2d(in_channels, 1024, 1, 2, bias=False)\n","        self.skip_bn = nn.BatchNorm2d(1024)\n","\n","        self.sepconv1 = SeparableConv(1024, 1536)\n","        self.sepconv2 = SeparableConv(1536, 2048)\n","        self.fc_layer = nn.Linear(2048, num_classes)\n","\n","    def forward(self, x):\n","        out = self.layers(x)\n","        out += self.skip_bn(self.skip_conv(x))\n","\n","        out = self.sepconv1(out)\n","        out = self.sepconv2(out)\n","        out = F.adaptive_avg_pool2d(out, (1, 1))\n","        out = out.view(out.size(0), -1)\n","        out = self.fc_layer(out)\n","        return out"],"execution_count":431,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BcshHi8_Q_co","executionInfo":{"status":"ok","timestamp":1621408742837,"user_tz":-540,"elapsed":2648,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"5c9417a2-9d0d-4564-805d-9b489c68eb22"},"source":["from torchsummary import summary\n","\n","model = Xception()\n","summary(model, (3, 299, 299))"],"execution_count":432,"outputs":[{"output_type":"stream","text":["exitflow\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 149, 149]             864\n","       BatchNorm2d-2         [-1, 32, 149, 149]              64\n","              ReLU-3         [-1, 32, 149, 149]               0\n","      StandardConv-4         [-1, 32, 149, 149]               0\n","            Conv2d-5         [-1, 64, 147, 147]          18,432\n","       BatchNorm2d-6         [-1, 64, 147, 147]             128\n","              ReLU-7         [-1, 64, 147, 147]               0\n","      StandardConv-8         [-1, 64, 147, 147]               0\n","            Conv2d-9         [-1, 64, 147, 147]             576\n","      BatchNorm2d-10         [-1, 64, 147, 147]             128\n","             ReLU-11         [-1, 64, 147, 147]               0\n","           Conv2d-12        [-1, 128, 147, 147]           8,192\n","      BatchNorm2d-13        [-1, 128, 147, 147]             256\n","             ReLU-14        [-1, 128, 147, 147]               0\n","    SeparableConv-15        [-1, 128, 147, 147]               0\n","             ReLU-16        [-1, 128, 147, 147]               0\n","           Conv2d-17        [-1, 128, 147, 147]           1,152\n","      BatchNorm2d-18        [-1, 128, 147, 147]             256\n","             ReLU-19        [-1, 128, 147, 147]               0\n","           Conv2d-20        [-1, 128, 147, 147]          16,384\n","      BatchNorm2d-21        [-1, 128, 147, 147]             256\n","             ReLU-22        [-1, 128, 147, 147]               0\n","    SeparableConv-23        [-1, 128, 147, 147]               0\n","        MaxPool2d-24          [-1, 128, 74, 74]               0\n","           Conv2d-25          [-1, 128, 74, 74]           8,192\n","      BatchNorm2d-26          [-1, 128, 74, 74]             256\n","            Block-27          [-1, 128, 74, 74]               0\n","             ReLU-28          [-1, 128, 74, 74]               0\n","           Conv2d-29          [-1, 128, 74, 74]           1,152\n","      BatchNorm2d-30          [-1, 128, 74, 74]             256\n","             ReLU-31          [-1, 128, 74, 74]               0\n","           Conv2d-32          [-1, 256, 74, 74]          32,768\n","      BatchNorm2d-33          [-1, 256, 74, 74]             512\n","             ReLU-34          [-1, 256, 74, 74]               0\n","    SeparableConv-35          [-1, 256, 74, 74]               0\n","             ReLU-36          [-1, 256, 74, 74]               0\n","           Conv2d-37          [-1, 256, 74, 74]           2,304\n","      BatchNorm2d-38          [-1, 256, 74, 74]             512\n","             ReLU-39          [-1, 256, 74, 74]               0\n","           Conv2d-40          [-1, 256, 74, 74]          65,536\n","      BatchNorm2d-41          [-1, 256, 74, 74]             512\n","             ReLU-42          [-1, 256, 74, 74]               0\n","    SeparableConv-43          [-1, 256, 74, 74]               0\n","        MaxPool2d-44          [-1, 256, 37, 37]               0\n","           Conv2d-45          [-1, 256, 37, 37]          32,768\n","      BatchNorm2d-46          [-1, 256, 37, 37]             512\n","            Block-47          [-1, 256, 37, 37]               0\n","             ReLU-48          [-1, 256, 37, 37]               0\n","           Conv2d-49          [-1, 256, 37, 37]           2,304\n","      BatchNorm2d-50          [-1, 256, 37, 37]             512\n","             ReLU-51          [-1, 256, 37, 37]               0\n","           Conv2d-52          [-1, 728, 37, 37]         186,368\n","      BatchNorm2d-53          [-1, 728, 37, 37]           1,456\n","             ReLU-54          [-1, 728, 37, 37]               0\n","    SeparableConv-55          [-1, 728, 37, 37]               0\n","             ReLU-56          [-1, 728, 37, 37]               0\n","           Conv2d-57          [-1, 728, 37, 37]           6,552\n","      BatchNorm2d-58          [-1, 728, 37, 37]           1,456\n","             ReLU-59          [-1, 728, 37, 37]               0\n","           Conv2d-60          [-1, 728, 37, 37]         529,984\n","      BatchNorm2d-61          [-1, 728, 37, 37]           1,456\n","             ReLU-62          [-1, 728, 37, 37]               0\n","    SeparableConv-63          [-1, 728, 37, 37]               0\n","        MaxPool2d-64          [-1, 728, 19, 19]               0\n","           Conv2d-65          [-1, 728, 19, 19]         186,368\n","      BatchNorm2d-66          [-1, 728, 19, 19]           1,456\n","            Block-67          [-1, 728, 19, 19]               0\n","        EntryFlow-68          [-1, 728, 19, 19]               0\n","             ReLU-69          [-1, 728, 19, 19]               0\n","           Conv2d-70          [-1, 728, 19, 19]           6,552\n","      BatchNorm2d-71          [-1, 728, 19, 19]           1,456\n","             ReLU-72          [-1, 728, 19, 19]               0\n","           Conv2d-73          [-1, 728, 19, 19]         529,984\n","      BatchNorm2d-74          [-1, 728, 19, 19]           1,456\n","             ReLU-75          [-1, 728, 19, 19]               0\n","    SeparableConv-76          [-1, 728, 19, 19]               0\n","             ReLU-77          [-1, 728, 19, 19]               0\n","           Conv2d-78          [-1, 728, 19, 19]           6,552\n","      BatchNorm2d-79          [-1, 728, 19, 19]           1,456\n","             ReLU-80          [-1, 728, 19, 19]               0\n","           Conv2d-81          [-1, 728, 19, 19]         529,984\n","      BatchNorm2d-82          [-1, 728, 19, 19]           1,456\n","             ReLU-83          [-1, 728, 19, 19]               0\n","    SeparableConv-84          [-1, 728, 19, 19]               0\n","             ReLU-85          [-1, 728, 19, 19]               0\n","           Conv2d-86          [-1, 728, 19, 19]           6,552\n","      BatchNorm2d-87          [-1, 728, 19, 19]           1,456\n","             ReLU-88          [-1, 728, 19, 19]               0\n","           Conv2d-89          [-1, 728, 19, 19]         529,984\n","      BatchNorm2d-90          [-1, 728, 19, 19]           1,456\n","             ReLU-91          [-1, 728, 19, 19]               0\n","    SeparableConv-92          [-1, 728, 19, 19]               0\n","            Block-93          [-1, 728, 19, 19]               0\n","             ReLU-94          [-1, 728, 19, 19]               0\n","           Conv2d-95          [-1, 728, 19, 19]           6,552\n","      BatchNorm2d-96          [-1, 728, 19, 19]           1,456\n","             ReLU-97          [-1, 728, 19, 19]               0\n","           Conv2d-98          [-1, 728, 19, 19]         529,984\n","      BatchNorm2d-99          [-1, 728, 19, 19]           1,456\n","            ReLU-100          [-1, 728, 19, 19]               0\n","   SeparableConv-101          [-1, 728, 19, 19]               0\n","            ReLU-102          [-1, 728, 19, 19]               0\n","          Conv2d-103          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-104          [-1, 728, 19, 19]           1,456\n","            ReLU-105          [-1, 728, 19, 19]               0\n","          Conv2d-106          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-107          [-1, 728, 19, 19]           1,456\n","            ReLU-108          [-1, 728, 19, 19]               0\n","   SeparableConv-109          [-1, 728, 19, 19]               0\n","            ReLU-110          [-1, 728, 19, 19]               0\n","          Conv2d-111          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-112          [-1, 728, 19, 19]           1,456\n","            ReLU-113          [-1, 728, 19, 19]               0\n","          Conv2d-114          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-115          [-1, 728, 19, 19]           1,456\n","            ReLU-116          [-1, 728, 19, 19]               0\n","   SeparableConv-117          [-1, 728, 19, 19]               0\n","           Block-118          [-1, 728, 19, 19]               0\n","            ReLU-119          [-1, 728, 19, 19]               0\n","          Conv2d-120          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-121          [-1, 728, 19, 19]           1,456\n","            ReLU-122          [-1, 728, 19, 19]               0\n","          Conv2d-123          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-124          [-1, 728, 19, 19]           1,456\n","            ReLU-125          [-1, 728, 19, 19]               0\n","   SeparableConv-126          [-1, 728, 19, 19]               0\n","            ReLU-127          [-1, 728, 19, 19]               0\n","          Conv2d-128          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-129          [-1, 728, 19, 19]           1,456\n","            ReLU-130          [-1, 728, 19, 19]               0\n","          Conv2d-131          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-132          [-1, 728, 19, 19]           1,456\n","            ReLU-133          [-1, 728, 19, 19]               0\n","   SeparableConv-134          [-1, 728, 19, 19]               0\n","            ReLU-135          [-1, 728, 19, 19]               0\n","          Conv2d-136          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-137          [-1, 728, 19, 19]           1,456\n","            ReLU-138          [-1, 728, 19, 19]               0\n","          Conv2d-139          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-140          [-1, 728, 19, 19]           1,456\n","            ReLU-141          [-1, 728, 19, 19]               0\n","   SeparableConv-142          [-1, 728, 19, 19]               0\n","           Block-143          [-1, 728, 19, 19]               0\n","            ReLU-144          [-1, 728, 19, 19]               0\n","          Conv2d-145          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-146          [-1, 728, 19, 19]           1,456\n","            ReLU-147          [-1, 728, 19, 19]               0\n","          Conv2d-148          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-149          [-1, 728, 19, 19]           1,456\n","            ReLU-150          [-1, 728, 19, 19]               0\n","   SeparableConv-151          [-1, 728, 19, 19]               0\n","            ReLU-152          [-1, 728, 19, 19]               0\n","          Conv2d-153          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-154          [-1, 728, 19, 19]           1,456\n","            ReLU-155          [-1, 728, 19, 19]               0\n","          Conv2d-156          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-157          [-1, 728, 19, 19]           1,456\n","            ReLU-158          [-1, 728, 19, 19]               0\n","   SeparableConv-159          [-1, 728, 19, 19]               0\n","            ReLU-160          [-1, 728, 19, 19]               0\n","          Conv2d-161          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-162          [-1, 728, 19, 19]           1,456\n","            ReLU-163          [-1, 728, 19, 19]               0\n","          Conv2d-164          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-165          [-1, 728, 19, 19]           1,456\n","            ReLU-166          [-1, 728, 19, 19]               0\n","   SeparableConv-167          [-1, 728, 19, 19]               0\n","           Block-168          [-1, 728, 19, 19]               0\n","            ReLU-169          [-1, 728, 19, 19]               0\n","          Conv2d-170          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-171          [-1, 728, 19, 19]           1,456\n","            ReLU-172          [-1, 728, 19, 19]               0\n","          Conv2d-173          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-174          [-1, 728, 19, 19]           1,456\n","            ReLU-175          [-1, 728, 19, 19]               0\n","   SeparableConv-176          [-1, 728, 19, 19]               0\n","            ReLU-177          [-1, 728, 19, 19]               0\n","          Conv2d-178          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-179          [-1, 728, 19, 19]           1,456\n","            ReLU-180          [-1, 728, 19, 19]               0\n","          Conv2d-181          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-182          [-1, 728, 19, 19]           1,456\n","            ReLU-183          [-1, 728, 19, 19]               0\n","   SeparableConv-184          [-1, 728, 19, 19]               0\n","            ReLU-185          [-1, 728, 19, 19]               0\n","          Conv2d-186          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-187          [-1, 728, 19, 19]           1,456\n","            ReLU-188          [-1, 728, 19, 19]               0\n","          Conv2d-189          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-190          [-1, 728, 19, 19]           1,456\n","            ReLU-191          [-1, 728, 19, 19]               0\n","   SeparableConv-192          [-1, 728, 19, 19]               0\n","           Block-193          [-1, 728, 19, 19]               0\n","            ReLU-194          [-1, 728, 19, 19]               0\n","          Conv2d-195          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-196          [-1, 728, 19, 19]           1,456\n","            ReLU-197          [-1, 728, 19, 19]               0\n","          Conv2d-198          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-199          [-1, 728, 19, 19]           1,456\n","            ReLU-200          [-1, 728, 19, 19]               0\n","   SeparableConv-201          [-1, 728, 19, 19]               0\n","            ReLU-202          [-1, 728, 19, 19]               0\n","          Conv2d-203          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-204          [-1, 728, 19, 19]           1,456\n","            ReLU-205          [-1, 728, 19, 19]               0\n","          Conv2d-206          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-207          [-1, 728, 19, 19]           1,456\n","            ReLU-208          [-1, 728, 19, 19]               0\n","   SeparableConv-209          [-1, 728, 19, 19]               0\n","            ReLU-210          [-1, 728, 19, 19]               0\n","          Conv2d-211          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-212          [-1, 728, 19, 19]           1,456\n","            ReLU-213          [-1, 728, 19, 19]               0\n","          Conv2d-214          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-215          [-1, 728, 19, 19]           1,456\n","            ReLU-216          [-1, 728, 19, 19]               0\n","   SeparableConv-217          [-1, 728, 19, 19]               0\n","           Block-218          [-1, 728, 19, 19]               0\n","            ReLU-219          [-1, 728, 19, 19]               0\n","          Conv2d-220          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-221          [-1, 728, 19, 19]           1,456\n","            ReLU-222          [-1, 728, 19, 19]               0\n","          Conv2d-223          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-224          [-1, 728, 19, 19]           1,456\n","            ReLU-225          [-1, 728, 19, 19]               0\n","   SeparableConv-226          [-1, 728, 19, 19]               0\n","            ReLU-227          [-1, 728, 19, 19]               0\n","          Conv2d-228          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-229          [-1, 728, 19, 19]           1,456\n","            ReLU-230          [-1, 728, 19, 19]               0\n","          Conv2d-231          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-232          [-1, 728, 19, 19]           1,456\n","            ReLU-233          [-1, 728, 19, 19]               0\n","   SeparableConv-234          [-1, 728, 19, 19]               0\n","            ReLU-235          [-1, 728, 19, 19]               0\n","          Conv2d-236          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-237          [-1, 728, 19, 19]           1,456\n","            ReLU-238          [-1, 728, 19, 19]               0\n","          Conv2d-239          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-240          [-1, 728, 19, 19]           1,456\n","            ReLU-241          [-1, 728, 19, 19]               0\n","   SeparableConv-242          [-1, 728, 19, 19]               0\n","           Block-243          [-1, 728, 19, 19]               0\n","            ReLU-244          [-1, 728, 19, 19]               0\n","          Conv2d-245          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-246          [-1, 728, 19, 19]           1,456\n","            ReLU-247          [-1, 728, 19, 19]               0\n","          Conv2d-248          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-249          [-1, 728, 19, 19]           1,456\n","            ReLU-250          [-1, 728, 19, 19]               0\n","   SeparableConv-251          [-1, 728, 19, 19]               0\n","            ReLU-252          [-1, 728, 19, 19]               0\n","          Conv2d-253          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-254          [-1, 728, 19, 19]           1,456\n","            ReLU-255          [-1, 728, 19, 19]               0\n","          Conv2d-256          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-257          [-1, 728, 19, 19]           1,456\n","            ReLU-258          [-1, 728, 19, 19]               0\n","   SeparableConv-259          [-1, 728, 19, 19]               0\n","            ReLU-260          [-1, 728, 19, 19]               0\n","          Conv2d-261          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-262          [-1, 728, 19, 19]           1,456\n","            ReLU-263          [-1, 728, 19, 19]               0\n","          Conv2d-264          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-265          [-1, 728, 19, 19]           1,456\n","            ReLU-266          [-1, 728, 19, 19]               0\n","   SeparableConv-267          [-1, 728, 19, 19]               0\n","           Block-268          [-1, 728, 19, 19]               0\n","      MiddleFlow-269          [-1, 728, 19, 19]               0\n","            ReLU-270          [-1, 728, 19, 19]               0\n","          Conv2d-271          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-272          [-1, 728, 19, 19]           1,456\n","            ReLU-273          [-1, 728, 19, 19]               0\n","          Conv2d-274          [-1, 728, 19, 19]         529,984\n","     BatchNorm2d-275          [-1, 728, 19, 19]           1,456\n","            ReLU-276          [-1, 728, 19, 19]               0\n","   SeparableConv-277          [-1, 728, 19, 19]               0\n","     BatchNorm2d-278          [-1, 728, 19, 19]           1,456\n","            ReLU-279          [-1, 728, 19, 19]               0\n","          Conv2d-280          [-1, 728, 19, 19]           6,552\n","     BatchNorm2d-281          [-1, 728, 19, 19]           1,456\n","            ReLU-282          [-1, 728, 19, 19]               0\n","          Conv2d-283         [-1, 1024, 19, 19]         745,472\n","     BatchNorm2d-284         [-1, 1024, 19, 19]           2,048\n","            ReLU-285         [-1, 1024, 19, 19]               0\n","   SeparableConv-286         [-1, 1024, 19, 19]               0\n","     BatchNorm2d-287         [-1, 1024, 19, 19]           2,048\n","       MaxPool2d-288         [-1, 1024, 10, 10]               0\n","          Conv2d-289         [-1, 1024, 10, 10]         745,472\n","     BatchNorm2d-290         [-1, 1024, 10, 10]           2,048\n","          Conv2d-291         [-1, 1024, 10, 10]           9,216\n","     BatchNorm2d-292         [-1, 1024, 10, 10]           2,048\n","            ReLU-293         [-1, 1024, 10, 10]               0\n","          Conv2d-294         [-1, 1536, 10, 10]       1,572,864\n","     BatchNorm2d-295         [-1, 1536, 10, 10]           3,072\n","            ReLU-296         [-1, 1536, 10, 10]               0\n","   SeparableConv-297         [-1, 1536, 10, 10]               0\n","          Conv2d-298         [-1, 1536, 10, 10]          13,824\n","     BatchNorm2d-299         [-1, 1536, 10, 10]           3,072\n","            ReLU-300         [-1, 1536, 10, 10]               0\n","          Conv2d-301         [-1, 2048, 10, 10]       3,145,728\n","     BatchNorm2d-302         [-1, 2048, 10, 10]           4,096\n","            ReLU-303         [-1, 2048, 10, 10]               0\n","   SeparableConv-304         [-1, 2048, 10, 10]               0\n","          Linear-305                   [-1, 10]          20,490\n","        ExitFlow-306                   [-1, 10]               0\n","================================================================\n","Total params: 20,877,042\n","Trainable params: 20,877,042\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.02\n","Forward/backward pass size (MB): 1104.88\n","Params size (MB): 79.64\n","Estimated Total Size (MB): 1185.54\n","----------------------------------------------------------------\n"],"name":"stdout"}]}]}