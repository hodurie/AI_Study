{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R-CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPGTAvo6LDzZWwQs00/BvCd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNKwCS6MFdt3","executionInfo":{"status":"ok","timestamp":1620107657070,"user_tz":-540,"elapsed":111497,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"387d4df5-7173-4481-ba78-eef0db19db01"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C06VKAAIF_jN","executionInfo":{"status":"ok","timestamp":1620107657899,"user_tz":-540,"elapsed":112317,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"958245da-d8f6-4c33-fbb6-c97b66728766"},"source":["%cd '/content/gdrive/MyDrive/PASCAL/VOCdevkit/VOC2007/'\n","%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/PASCAL/VOCdevkit/VOC2007\n","\u001b[0m\u001b[01;34mAnnotations\u001b[0m/  \u001b[01;34mImageSets\u001b[0m/      seg_df.csv\n","df.csv        \u001b[01;34mJPEGImages\u001b[0m/     \u001b[01;34mSegmentationClass\u001b[0m/\n","\u001b[01;34mFinetune\u001b[0m/     samples.pickle  \u001b[01;34mSegmentationObject\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1PFeWrJOOHEX","executionInfo":{"status":"ok","timestamp":1620112561991,"user_tz":-540,"elapsed":854,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"d6fc53ad-7194-4b41-867b-a3f169240a89"},"source":["%ls '/content/gdrive/MyDrive/PASCAL/VOCdevkit/VOC2007/Finetune/Annotations/'"],"execution_count":52,"outputs":[{"output_type":"stream","text":["000134_n.csv  002045_n.csv  004705_n.csv  005979_n.csv  008461_n.csv\n","000134_p.csv  002045_p.csv  004705_p.csv  005979_p.csv  008461_p.csv\n","000210_n.csv  002056_n.csv  004873_n.csv  006062_n.csv  008483_n.csv\n","000210_p.csv  002056_p.csv  004873_p.csv  006062_p.csv  008483_p.csv\n","000233_n.csv  002533_n.csv  004890_n.csv  006124_n.csv  008665_n.csv\n","000233_p.csv  002533_p.csv  004890_p.csv  006124_p.csv  008665_p.csv\n","000263_n.csv  002734_n.csv  004946_n.csv  006196_n.csv  008750_n.csv\n","000263_p.csv  002734_p.csv  004946_p.csv  006196_p.csv  008750_p.csv\n","000477_n.csv  002804_n.csv  005067_n.csv  006224_n.csv  008768_n.csv\n","000477_p.csv  002804_p.csv  005067_p.csv  006224_p.csv  008768_p.csv\n","000860_n.csv  003195_n.csv  005199_n.csv  006235_n.csv  008923_n.csv\n","000860_p.csv  003195_p.csv  005199_p.csv  006235_p.csv  008923_p.csv\n","000906_n.csv  003355_n.csv  005483_n.csv  006375_n.csv  008939_n.csv\n","000906_p.csv  003355_p.csv  005483_p.csv  006375_p.csv  008939_p.csv\n","001069_n.csv  003363_n.csv  005566_n.csv  007003_n.csv  008960_n.csv\n","001069_p.csv  003363_p.csv  005566_p.csv  007003_p.csv  008960_p.csv\n","001119_n.csv  003390_n.csv  005585_n.csv  007068_n.csv  008968_n.csv\n","001119_p.csv  003390_p.csv  005585_p.csv  007068_p.csv  008968_p.csv\n","001292_n.csv  003420_n.csv  005588_n.csv  007283_n.csv  009073_n.csv\n","001292_p.csv  003420_p.csv  005588_p.csv  007283_p.csv  009073_p.csv\n","001352_n.csv  003461_n.csv  005593_n.csv  007855_n.csv  009179_n.csv\n","001352_p.csv  003461_p.csv  005593_p.csv  007855_p.csv  009179_p.csv\n","001693_n.csv  003987_n.csv  005609_n.csv  007963_n.csv  009205_n.csv\n","001693_p.csv  003987_p.csv  005609_p.csv  007963_p.csv  009205_p.csv\n","001862_n.csv  004295_n.csv  005749_n.csv  008108_n.csv  009558_n.csv\n","001862_p.csv  004295_p.csv  005749_p.csv  008108_p.csv  009558_p.csv\n","001899_n.csv  004576_n.csv  005756_n.csv  008279_n.csv  009900_n.csv\n","001899_p.csv  004576_p.csv  005756_p.csv  008279_p.csv  009900_p.csv\n","001944_n.csv  004591_n.csv  005897_n.csv  008360_n.csv  009932_n.csv\n","001944_p.csv  004591_p.csv  005897_p.csv  008360_p.csv  009932_p.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ww7vFLpvOYuK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHwHfwa4Oks9"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import random\n","\n","import cv2\n","\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PBfv8B6MPXQK"},"source":["전처리한 df [Object Detection.ipynb](https://github.com/hodurie/AI_Study/blob/master/Implementation/Datasets/Object%20Detection.ipynb)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"OyVDauEYO-6p","executionInfo":{"status":"ok","timestamp":1620107660018,"user_tz":-540,"elapsed":1452,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"2b9d9afd-276b-476c-b588-5e7b194cec7d"},"source":["df = pd.read_csv('df.csv')\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>file_type</th>\n","      <th>object_length</th>\n","      <th>object</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","      <th>pose</th>\n","      <th>truncated</th>\n","      <th>difficult</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000012.jpg</td>\n","      <td>train</td>\n","      <td>1</td>\n","      <td>car</td>\n","      <td>156</td>\n","      <td>97</td>\n","      <td>351</td>\n","      <td>270</td>\n","      <td>Rear</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000017.jpg</td>\n","      <td>train</td>\n","      <td>2</td>\n","      <td>person</td>\n","      <td>185</td>\n","      <td>62</td>\n","      <td>279</td>\n","      <td>199</td>\n","      <td>Left</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000017.jpg</td>\n","      <td>train</td>\n","      <td>2</td>\n","      <td>horse</td>\n","      <td>90</td>\n","      <td>78</td>\n","      <td>403</td>\n","      <td>336</td>\n","      <td>Left</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>000023.jpg</td>\n","      <td>train</td>\n","      <td>6</td>\n","      <td>bicycle</td>\n","      <td>9</td>\n","      <td>230</td>\n","      <td>245</td>\n","      <td>500</td>\n","      <td>Unspecified</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000023.jpg</td>\n","      <td>train</td>\n","      <td>6</td>\n","      <td>bicycle</td>\n","      <td>230</td>\n","      <td>220</td>\n","      <td>334</td>\n","      <td>500</td>\n","      <td>Frontal</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    file_name file_type  object_length  ...         pose  truncated  difficult\n","0  000012.jpg     train              1  ...         Rear          0          0\n","1  000017.jpg     train              2  ...         Left          0          0\n","2  000017.jpg     train              2  ...         Left          0          0\n","3  000023.jpg     train              6  ...  Unspecified          1          0\n","4  000023.jpg     train              6  ...      Frontal          1          0\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"u3pnIe21UD_y"},"source":["PASCAL VOC 2007 directory\n","```\n","/VOCdevkit//VOC2007/\n","├── df.csv                # Object Detection 전처리 csv\n","├── seg.csv               # Segmentation 전처리 csv\n","└── Finetune              # positive_list, negative_list txt 폴더\n","     ├── train\n","     │   ├── *_n.csv / *_p.csv\n","     │   ├── Annotations\n","     │   └── bndboxes\n","     └── validation\n","          └── Annotations\n","\n","\n","# 기존 PASCAL VOC 2007 directory 구조\n","/VOCdevkit//VOC2007/\n","├── Annotations           \n","│   └── *.xml        \n","├── ImageSets\n","│   ├── Layout\n","│   │   └── *.txt\n","│   ├── Main\n","│   │   └── *.txt\n","│   └── Segmentation\n","│        └── *.txt\n","├── JPEGImages\n","│   └── .jpg\n","├── SegmentationClass\n","│   └── *.png\n","└── SegmentationObject\n","     └── *.png\n","\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"ZhbD143eTpxD","executionInfo":{"status":"ok","timestamp":1620112683268,"user_tz":-540,"elapsed":625,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["finetune_root_dir = './Finetune/'\n","\n","if not os.path.exists(finetune_root_dir):\n","    os.mkdir(finetune_root_dir)\n","\n","for name in ['train', 'validation']:\n","    dst_root_dir = os.path.join(finetune_root_dir, name)\n","\n","    if not os.path.exists(dst_root_dir):\n","        os.mkdir(dst_root_dir)\n","\n","    dst_annotation_dir = os.path.join(finetune_root_dir, name, 'Annotations')\n","    if not os.path.exists(dst_annotation_dir):\n","        os.mkdir(dst_annotation_dir)"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lnPlpt168IR9"},"source":["특정 obj 만 추출해서 sample 만들기"]},{"cell_type":"code","metadata":{"id":"OLDGmksvtR5s"},"source":["def sample_split(df, obj='car'):\n","    # car dataset 사용\n","    cond = df['object'] == obj\n","    df = df[cond]\n","\n","    samples = {}\n","\n","    for name in ['train', 'validation']:\n","        cond = df['file_type'] == name\n","        sample = df.loc[cond, 'file_name'].unique()\n","\n","        length = len(sample)\n","        \n","        indices = random.sample(range(length), int(length/ 10))\n","        \n","        samples[name] = sample[indices]\n","\n","    return samples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m220Q3t9wSIq"},"source":["def IoU(pred_box, target_box):\n","    '''\n","    pred_box = [4] \n","    target_box = [N, 4]\n","    '''\n","    # (xmax - xmin) * (ymax - ymin)\n","\n","    if len(target_box.shape) == 1:\n","        target_box = target_box[np.newaxis, :]\n","\n","    areaA = (target_box[:, 2] - target_box[:, 0]) * (target_box[:, 3] - target_box[:, 1])\n","    areaB = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n","\n","    xA = np.maximum(pred_box[0], target_box[:, 0])\n","    yA = np.maximum(pred_box[1], target_box[:, 1])\n","    xB = np.minimum(pred_box[2], target_box[:, 2])\n","    yB = np.minimum(pred_box[3], target_box[:, 3])\n","    \n","    intersection = np.maximum(0.0, xB - xA) * np.maximum(0.0, yB - yA)\n","    \n","    scores = intersection / (areaA + areaB - intersection)\n","\n","\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmlkJ8tTwy2s"},"source":["def region_proposals(jpg, gs):\n","    global df\n","    path = os.path.join('./JPEGImages/', jpg)\n","    img = cv2.imread(path)\n","\n","    gs.setBaseImage(img)\n","    gs.switchToSelectiveSearchQuality()\n","\n","    rects = gs.process()\n","    rects[:, 2] += rects[:, 0]\n","    rects[:, 3] += rects[:, 1]\n","\n","    cond = df['file_name'] == jpg\n","    cols = ['xmin', 'ymin', 'xmax', 'ymax']\n","    bndboxes = np.array(df.loc[cond, cols])\n","\n","    maximum_bndbox_size = 0\n","\n","    for bndbox in bndboxes:\n","        xmin, ymin, xmax, ymax = bndbox\n","        bndbox_size = (xmax - xmin) * (ymax - ymin)\n","        if bndbox_size > maximum_bndbox_size:\n","            maximum_bndbox_size = bndbox_size\n","\n","\n","    iou_list = []\n","    for rect in rects:\n","        scores = IoU(rect, bndboxes)\n","        iou_list.append(max(scores))\n","    \n","    return iou_list, rects, maximum_bndbox_size, bndboxes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7hsD6Xe0Flf0"},"source":["def parse_annotation_jpg(jpg, gs):\n","    iou_list, rects, maximum_bndbox_size, bndboxes = region_proposals(jpg, gs)\n","\n","    positive_list = []\n","    negative_list = []\n","\n","    for i in range(len(iou_list)):\n","        xmin, ymin, xmax, ymax = rects[i]\n","        rect_size = (xmax - xmin) * (ymax - ymin)\n","\n","        iou_score = iou_list[i]\n","\n","        if iou_score >= 0.5:\n","            positive_list.append(rects[i])\n","        \n","        if 0 < iou_score < 0.5 and rect_size > maximum_bndbox_size / 5.0:\n","            negative_list.append(rects[i])\n","    \n","    return positive_list, negative_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_e_8EAS8XlU"},"source":["gs = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n","\n","samples = sample_split(df)\n","\n","for name in ['train', 'validation']:\n","    total_num_positive = 0\n","    total_num_negative = 0\n","\n","\n","    for sample in samples[name]:\n","        positive_list, negative_list = parse_annotation_jpg(sample, gs)\n","        total_num_positive += len(positive_list)\n","        total_num_negative += len(negative_list)\n","\n","        finetune_path = os.path.join(finetune_root_dir, name)\n","\n","        positive_list_path = os.path.join(finetune_path, sample.replace('.jpg', '_p.csv'))\n","        negative_list_path = os.path.join(finetune_path, sample.replace('.jpg', '_n.csv'))\n","        \n","        np.savetxt(positive_list_path, np.array(positive_list), fmt='%d', delimiter=' ')\n","        np.savetxt(negative_list_path, np.array(negative_list), fmt='%d', delimiter=' ')\n","\n","    print('%s positive num: %d' % (name, total_num_positive))\n","    print('%s negative num: %d' % (name, total_num_negative))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3OPLa7ztb3Y"},"source":["with open('samples.pickle','wb') as fw:\n","    pickle.dump(samples, fw)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V209Gly2t4XT"},"source":["with open('samples.pickle', 'rb') as fr:\n","    samples = pickle.load(fr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y0ltv0AMxTiR","executionInfo":{"status":"ok","timestamp":1620107738411,"user_tz":-540,"elapsed":781,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"f586077d-307b-4881-bd4c-cb675b951093"},"source":["samples"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'train': array(['000906.jpg', '008968.jpg', '005585.jpg', '005609.jpg',\n","        '008108.jpg', '004946.jpg', '008665.jpg', '005483.jpg',\n","        '002533.jpg', '008750.jpg', '008923.jpg', '008483.jpg',\n","        '003355.jpg', '002056.jpg', '004873.jpg', '008960.jpg',\n","        '009073.jpg', '005566.jpg', '008768.jpg', '002804.jpg',\n","        '003987.jpg', '008360.jpg', '006224.jpg', '004576.jpg',\n","        '003420.jpg', '006375.jpg', '005756.jpg', '003363.jpg',\n","        '000134.jpg', '004591.jpg', '000860.jpg', '009205.jpg',\n","        '006196.jpg', '000477.jpg', '007003.jpg', '004705.jpg',\n","        '008939.jpg', '001119.jpg', '000263.jpg', '007963.jpg'],\n","       dtype=object),\n"," 'validation': array(['006235.jpg', '002045.jpg', '003390.jpg', '002734.jpg',\n","        '005979.jpg', '001944.jpg', '003461.jpg', '008461.jpg',\n","        '007855.jpg', '009900.jpg', '000233.jpg', '005593.jpg',\n","        '009558.jpg', '001862.jpg', '009932.jpg', '006062.jpg',\n","        '001693.jpg', '008279.jpg', '004295.jpg', '005749.jpg',\n","        '009179.jpg', '007283.jpg', '003195.jpg', '001352.jpg',\n","        '005897.jpg', '001069.jpg', '005199.jpg', '001292.jpg',\n","        '005067.jpg', '005588.jpg', '001899.jpg', '006124.jpg',\n","        '000210.jpg', '004890.jpg', '007068.jpg'], dtype=object)}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"cPgKw6MJ-va9"},"source":["def parse_annotation_jpg_svm(jpg, gs):\n","    iou_list, rects, maximum_bndbox_size, bndboxs = region_proposals(jpg, gs)\n","\n","    positive_list = []\n","    negative_list = []\n","\n","    for i in range(len(iou_list)):\n","        xmin, ymin, xmax, ymax = rects[i]\n","        rect_size = (xmax - xmin) * (ymax - ymin)\n","\n","        iou_score = iou_list[i]\n","\n","        if 0 < iou_score <= 0.3 and rect_size > maximum_bndbox_size / 5.0:\n","            negative_list.append(rects[i])\n","\n","        return bndboxs, negative_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IrnYfVMiAGF0","executionInfo":{"status":"ok","timestamp":1620113361932,"user_tz":-540,"elapsed":576121,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"2409097c-69d3-426c-9099-a133088d83c3"},"source":["gs = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n","\n","for name in ['train', 'validation']:\n","    total_num_positive = 0\n","    total_num_negative = 0\n","\n","    for sample in samples[name]:\n","        positive_list, negative_list = parse_annotation_jpg_svm(sample, gs)\n","        total_num_positive += len(positive_list)\n","        total_num_negative += len(negative_list)\n","\n","        path = os.path.join(finetune_root_dir, name, 'Annotations')\n","        dst_annotation_positive_path = os.path.join(path, sample.replace('.jpg', '_p.csv'))\n","        dst_annotation_negative_path = os.path.join(path, sample.replace('.jpg', '_n.csv'))\n","\n","        np.savetxt(dst_annotation_positive_path, np.array(positive_list), fmt='%d', delimiter=' ')\n","        np.savetxt(dst_annotation_negative_path, np.array(negative_list), fmt='%d', delimiter=' ')\n","    \n","    print('%s positive num: %d' % (name, total_num_positive))\n","    print('%s negative num: %d' % (name, total_num_negative))"],"execution_count":54,"outputs":[{"output_type":"stream","text":["train positive num: 167\n","train negative num: 4\n","validation positive num: 171\n","validation negative num: 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FwBVKoF4I22j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620113723171,"user_tz":-540,"elapsed":1744,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"dc6f54ec-ebe6-4679-d598-75476f7a3953"},"source":["res_samples = []\n","total_positive_num = 0\n","\n","name = 'train'\n","\n","jpg_csv_path = os.path.join(finetune_root_dir, name, 'bndboxes')\n","if not os.path.exists(jpg_csv_path):\n","    os.mkdir(jpg_csv_path)\n","\n","for sample in samples[name]:\n","    path = os.path.join(finetune_root_dir, name, sample.replace('.jpg', '_p.csv'))\n","    positive_bndboxes = np.loadtxt(path, dtype=np.int, delimiter=' ')\n","\n","    cols = ['xmin', 'ymin', 'xmax', 'ymax']\n","    train_df = df[df['file_name'] == sample]\n","    train_car = train_df.loc[df['object'] == 'car']\n","\n","    bndboxes = np.array(train_car[cols])\n","    \n","    positive_list = []\n","\n","    if len(positive_bndboxes.shape) == 1 and len(positive_bndboxes) != 0:\n","        scores = iou(positive_bndboxes, bndboxes)\n","        if np.max(scores) > 0.6:\n","            positive_list.append(positive_bndboxes)\n","    elif len(positive_bndboxes.shape) == 2:\n","        for positive_bndbox in positive_bndboxes:\n","            scores = IoU(positive_bndbox, bndboxes)\n","            if np.max(scores) > 0.6:\n","                positive_list.append(positive_bndbox)\n","\n","    if len(positive_list) > 0:\n","        jpg_csv_paths = os.path.join(jpg_csv_path, sample.replace('jpg', 'csv'))\n","        np.savetxt(jpg_csv_paths, np.array(positive_list), fmt='%s', delimiter=' ')\n","        total_positive_num += len(positive_list)\n","        res_samples.append(sample)\n","        print('save {} done'.format(sample))\n","    else:\n","        print('-------- {} ineligible'.format(sample))\n","\n","dst_csv_path = os.path.join(finetune_root_dir, name, 'bndboxes', 'df.csv')\n","np.savetxt(dst_csv_path, res_samples, fmt='%s', delimiter=' ')\n","print('total positive num: {}'.format(total_positive_num))"],"execution_count":70,"outputs":[{"output_type":"stream","text":["save 000906.jpg done\n","save 008968.jpg done\n","save 005585.jpg done\n","save 005609.jpg done\n","save 008108.jpg done\n","save 004946.jpg done\n","save 008665.jpg done\n","save 005483.jpg done\n","save 002533.jpg done\n","save 008750.jpg done\n","save 008923.jpg done\n","save 008483.jpg done\n","save 003355.jpg done\n","-------- 002056.jpg ineligible\n","save 004873.jpg done\n","-------- 008960.jpg ineligible\n","save 009073.jpg done\n","save 005566.jpg done\n","save 008768.jpg done\n","save 002804.jpg done\n","save 003987.jpg done\n","save 008360.jpg done\n","save 006224.jpg done\n","save 004576.jpg done\n","save 003420.jpg done\n","save 006375.jpg done\n","save 005756.jpg done\n","save 003363.jpg done\n","save 000134.jpg done\n","save 004591.jpg done\n","save 000860.jpg done\n","save 009205.jpg done\n","save 006196.jpg done\n","-------- 000477.jpg ineligible\n","save 007003.jpg done\n","save 004705.jpg done\n","save 008939.jpg done\n","save 001119.jpg done\n","save 000263.jpg done\n","save 007963.jpg done\n","total positive num: 4474\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"StBRteg2YoRE","executionInfo":{"status":"ok","timestamp":1620115167772,"user_tz":-540,"elapsed":611,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztx-68tEG0do","executionInfo":{"status":"ok","timestamp":1620115917651,"user_tz":-540,"elapsed":834,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class CustomFinetuneDataset():\n","    def __init__(self, root_dir, transform=None):\n","        '''\n","        root_dir = 'Finetune/train'\n","        jpg_path = 'JPEGImages/'\n","        '''\n","        with open('samples.pickle', 'rb') as fr:\n","            samples = pickle.load(fr)\n","\n","        name = root_dir.split('/')[-1]\n","\n","        jpg_path = './JPEGImages/'\n","\n","        images = [cv2.imread(os.path.join(jpg_path, sample)) for sample in samples[name]]\n","\n","        annotations_path = os.path.join(root_dir, 'Annotations')\n","        positive_annotations = [cv2.imread(os.path.join(annotations_path, sample.replace('.jpg', '_p.csv'))) for sample in samples[name]]\n","        negative_annotations = [cv2.imread(os.path.join(annotations_path, sample.replace('.jpg', '_n.csv'))) for sample in samples[name]]\n","\n","        positive_sizes = []\n","        negative_sizes = []\n","        \n","        positive_rects = []\n","        negative_rects = []\n","\n","        for annotation_path in positive_annotations:\n","            rects = np.loadtxt(annotation_path, dtype=np.int, delimiter=' ')\n","            if len(rects.shape) == 1:\n","                if rects.shape[0] == 4:\n","                    positive_rects.append(rects)\n","                    positive_sizes.append(1)\n","                else:\n","                    positive_sizes.append(0)\n","            else:\n","                positive_rects.extend(rects)\n","                positive_sizes.append(len(rects))\n","        \n","        for annotation_path in negative_annotations:\n","            rects = np.loadtxt(annotation_path, dtype=np.int, delimiter=' ')\n","            if len(rects.shape) == 1:\n","                if rects.shape[0] == 4:\n","                    negative_rects.append(rects)\n","                    negative_sizes.append(1)\n","                else:\n","                    positive_sizes.append(0)\n","            else:\n","                negative_rects.extend(rects)\n","                negative_sizes.append(len(rects))\n","\n","        self.transform = transform\n","        self.images = images\n","        self.positive_sizes = positive_sizes\n","        self.negative_sizes = negative_sizes\n","        self.positive_rects = positive_rects\n","        self.negative_rects = negative_rects\n","        self.total_positive_num = int(np.sum(positive_sizes))\n","        self.total_negative_num = int(np.sum(negative_sizes))\n","    \n","    def __getitem__(self, index):\n","        image_id = len(self.images) - 1\n","        if index < self.total_positive_num:\n","            target = 1\n","            xmin, ymin, xmax, ymax = self.positive_rects[index]\n","\n","            for i in range(len(self.positive_sizes) - 1):\n","                if np.sum(self.positive_sizes[:i]) <= index < np.sum(self.positive_sizes[:(i + 1)]):\n","                    image_id = i\n","                    break\n","            image = self.images[image_id][ymin:ymax, xmin:xmax]\n","        else:\n","            target = 0\n","            idx = index - self.total_positive_num\n","            xmin, ymin, xmax, ymax = self.negative_rects[idx]\n","\n","            for i in range(len(self.negative_sizes) - 1):\n","                if np.sum(self.negative_sizes[:i]) <= idx < np.sum(self.negative_sizes[:(i + 1)]):\n","                    image_id = i\n","                    break\n","            image = self.jpeg_images[image_id][ymin:ymax, xmin:xmax]\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, target\n","\n","    def __len__(self):\n","        return self.total_positive_num + self.total_negative_num\n","\n","    def get_positive_num(self):\n","        return self.total_positive_num\n","\n","    def get_negative_num(self):\n","        return self.total_negative_num"],"execution_count":111,"outputs":[]},{"cell_type":"code","metadata":{"id":"sTdtMELPpwiD","executionInfo":{"status":"ok","timestamp":1620115920072,"user_tz":-540,"elapsed":634,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["from google.colab.patches import cv2_imshow\n","\n","def test_finetune(idx):\n","    root_dir = './Finetune/train'\n","    train_data_set = CustomFinetuneDataset(root_dir)\n","\n","    print('positive num: %d' % train_data_set.get_positive_num())\n","    print('negative num: %d' % train_data_set.get_negative_num())\n","    print('total num: %d' % train_data_set.__len__())\n","\n","    image, target = train_data_set.__getitem__(idx)\n","    print('target: %d' % target)\n","\n","    cv2_imshow(image)\n","    cv2.waitKey(0)"],"execution_count":112,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U0SE90pjOPYr"},"source":["## Reference\n","- [R-CNN](https://github.com/object-detection-algorithm/R-CNN)\n","\n","```\n","@misc{girshick2013rich,\n","    title={Rich feature hierarchies for accurate object detection and semantic segmentation},\n","    author={Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},\n","    year={2013},\n","    eprint={1311.2524},\n","    archivePrefix={arXiv},\n","    primaryClass={cs.CV}\n","}\n","\n","@misc{pascal-voc-2007,\n","\tauthor = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n","\ttitle = \"The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2007 {(VOC2007)} {R}esults\",\n","\thowpublished = \"http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html\"}\n","\n","```"]}]}