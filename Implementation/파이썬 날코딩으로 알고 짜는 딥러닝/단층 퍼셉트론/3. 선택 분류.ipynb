{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3. 선택 분류.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN4wFTSFPPdTjDa9jEHuJay"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vs4cr20f5wSx"},"source":["# 선택 분류"]},{"cell_type":"markdown","metadata":{"id":"XlhxW-GDL0Fz"},"source":["## 소프트맥스 함수\r\n","소프트맥스 함수는 로짓값 벡터를 확률 분포 벡터로 변환해주는 비선형 함수이다.  \r\n","\r\n","신경망이 어떤 값을 선택했는지는 로짓값 벡터만으로도 알 수 있지만, 우리는 확률 분포로 변환하는 과정을 거친다.  \r\n","이에 대한 두가지 이유가 존재한다.\r\n","1. 사용자가 확률 분포를 눈으로 확인하기 싶을 경우\r\n","2. 손실 함수에 대한 편미분을 구해야 하는 경우\r\n","\r\n","우리는 위의 두 가지 이유로 소프트맥스 함수가 필요하고 식은 다음과 같이 나타낸다.  \r\n","\r\n","$$ y_i = \\frac{e^{x_i}}{e^{x_1} + \\cdots + e^{x_n}} $$  \r\n","\r\n","하지만 위의 식은 계산 과정에서 오류를 일으킬 수 있기에 다음과 같은 변형식을 이용한다.  \r\n","\r\n","$$ y_i = \\frac{e^{x_i-x_k}}{e^{x_1-x_k} + \\cdots + e^{x_n-x_k}} $$  \r\n"]},{"cell_type":"markdown","metadata":{"id":"VMbtjpAKOzpS"},"source":["### 소프트맥스 교차 엔트로피\r\n","로짓 벡터 $a_1, a_2, \\cdots, a_n$과 정답 벡터 $y_1, y_2, \\cdots, y_n$이 존재한다고 가정하자.  \r\n","이때, 정답 벡터의 확률 분포가 $P$ 이고 로짓 벡터에 소프트맥스 함수를 적용하여 얻은 확률 분포를 $Q$라 하면  \r\n","\r\n","$$ H(P, Q) = -\\sum\\,p_ilog\\,q_i \\approx -\\sum\\,p_ilog(q_i + \\epsilon)$$"]},{"cell_type":"markdown","metadata":{"id":"_AZ-gZM73GJ_"},"source":["### 소프트맥스 교차 엔트로피의 편미분\r\n","추정 로짓 벡터가 $x_1, x_2, \\cdots, x_n$이고, 데이터로 주어진 정답 벡터가 $p_1, p_2, \\cdots, p_n$ 이라고 하자.  \r\n","이때 소프트맥스 함수를 이용하여 로직 벡터의 확률 분포를 추정한 값이 $q_1, q_2, \\cdots, q_n$ 이라 할 때 소프트맥스 교차 엔트로피의 편미분은 다음과 같다.  \r\n","\r\n","$$ \\frac{\\partial{H}}{\\partial{x_i}} = q_i - p_i $$"]},{"cell_type":"markdown","metadata":{"id":"IuHXXq_v4zd5"},"source":["## 불량 철판 판별 신경망"]},{"cell_type":"markdown","metadata":{"id":"DUxI5bJQVF7B"},"source":["### 불량 철판 데이터\r\n","철판의 표면 상태가 불량인지 아닌지, 불량이라면 어떤 종류의 결함을 갖고 있는지를 판별하여 철판 상태를 7가지로 분류한 데이터"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Habu7giIVfe2","executionInfo":{"status":"ok","timestamp":1612078377704,"user_tz":-540,"elapsed":1402,"user":{"displayName":"Ho","photoUrl":"","userId":"04796031619100753677"}},"outputId":"79be4f52-8a7f-48e1-9864-76082f9c6fd2"},"source":["!wget -O faults.txt https://archive.ics.uci.edu/ml/machine-learning-databases/00198/Faults.NNA"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-01-31 07:32:56--  https://archive.ics.uci.edu/ml/machine-learning-databases/00198/Faults.NNA\n","Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n","Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 299482 (292K) [application/x-httpd-php]\n","Saving to: ‘faults.txt’\n","\n","faults.txt          100%[===================>] 292.46K  1.10MB/s    in 0.3s    \n","\n","2021-01-31 07:32:57 (1.10 MB/s) - ‘faults.txt’ saved [299482/299482]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kSFpMHuXxkds"},"source":["### 파이썬 모듈 불러들이기"]},{"cell_type":"code","metadata":{"id":"PwJM-UcNYkUi"},"source":["import numpy as np\r\n","import time\r\n","\r\n","np.random.seed(1234)\r\n","\r\n","def randomize():\r\n","    np.random.seed(time.time())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oYuLCSWvxsg0"},"source":["### 하이퍼파라미터값의 정의"]},{"cell_type":"code","metadata":{"id":"Xf6FD_9nY582"},"source":["RND_MEAN = 0\r\n","RND_STD = 0.0030\r\n","\r\n","LEARNING_RATE = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sw6SofzDX1hr"},"source":["### 메인 함수 정의"]},{"cell_type":"code","metadata":{"id":"UDBmsaMTV-yp"},"source":["def steel_exec(epoch_count=10, mb_size=10, report=1):\r\n","    load_steel_dataset()\r\n","    init_model()\r\n","    train_and_test(epoch_count, mb_size, report)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_ey7fMjYX2y"},"source":["### 데이터 적재 함수 정의"]},{"cell_type":"code","metadata":{"id":"LF03ua29YZ32"},"source":["def load_steel_dataset():\r\n","    with open('faults.txt', 'r') as f:\r\n","        rows = []\r\n","        lines = f.readlines()\r\n","        for line in lines:\r\n","            row = [np.float32(value.strip()) for value in line.split('\\t')]\r\n","            rows.append(row)\r\n","\r\n","    global data, input_cnt, output_cnt\r\n","    input_cnt, output_cnt = 27, 7\r\n","    data = np.asarray(rows, dtype='float32')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pIc4YZUKa86y"},"source":["### 파라미터 초기화 함수 정의"]},{"cell_type":"code","metadata":{"id":"A69vi_JUa_UR"},"source":["def init_model():\r\n","    global weight, bias, input_cnt, output_cnt\r\n","    weight = np.random.normal(RND_MEAN, RND_STD, [input_cnt, output_cnt])\r\n","    bias = np.zeros([output_cnt])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frOM8KoybVoZ"},"source":["### 학습 및 평가 함수 정의"]},{"cell_type":"code","metadata":{"id":"hQF-ukoDbYFG"},"source":["def train_and_test(epoch_count, mb_size, report):\r\n","    step_count = arrange_data(mb_size)\r\n","    test_x, test_y = get_test_data()\r\n","    \r\n","    for epoch in range(epoch_count):\r\n","        losses, accs = [], []\r\n","        \r\n","        for n in range(step_count):\r\n","            train_x, train_y = get_train_data(mb_size, n)\r\n","            loss, acc = run_train(train_x, train_y)\r\n","            losses.append(loss)\r\n","            accs.append(acc)\r\n","            \r\n","        if report > 0 and (epoch+1) % report == 0:\r\n","            acc = run_test(test_x, test_y)\r\n","            print('Epoch {}: loss={:5.3f}, accuracy={:5.3f}/{:5.3f}'. \\\r\n","                  format(epoch+1, np.mean(losses), np.mean(accs), acc))\r\n","            \r\n","    final_acc = run_test(test_x, test_y)\r\n","    print('\\nFinal Test: final accuracy = {:5.3f}'.format(final_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dg3wnsZXBqN-"},"source":["### 학습 및 평가  데이터 획득 함수 정의"]},{"cell_type":"code","metadata":{"id":"3797l5t5m_7w"},"source":["def arrange_data(mb_size):\r\n","    global data, shuffle_map, test_begin_idx\r\n","    shuffle_map = np.arange(data.shape[0])\r\n","    np.random.shuffle(shuffle_map)\r\n","    step_count = int(data.shape[0] * 0.8) // mb_size\r\n","    test_begin_idx = step_count * mb_size\r\n","    return step_count\r\n","\r\n","def get_test_data():\r\n","    global data, shuffle_map, test_begin_idx, output_cnt\r\n","    test_data = data[shuffle_map[test_begin_idx:]]\r\n","    return test_data[:, :-output_cnt], test_data[:, -output_cnt:]\r\n","\r\n","def get_train_data(mb_size, nth):\r\n","    global data, shuffle_map, test_begin_idx, output_cnt\r\n","    if nth == 0:\r\n","        np.random.shuffle(shuffle_map[:test_begin_idx])\r\n","    train_data = data[shuffle_map[mb_size*nth:mb_size*(nth+1)]]\r\n","    return train_data[:, :-output_cnt], train_data[:, -output_cnt:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZP_bPQ6GBwph"},"source":["### 학습 실행 함수와 평가 실행 함수 정의"]},{"cell_type":"code","metadata":{"id":"N9GSMi2GoIwr"},"source":["def run_train(x, y):\r\n","    output, aux_nn = forward_neuralnet(x)\r\n","    loss, aux_pp = forward_postproc(output, y)\r\n","    accuracy = eval_accuracy(output, y)\r\n","    \r\n","    G_loss = 1.0\r\n","    G_output = backprop_postproc(G_loss, aux_pp)\r\n","    backprop_neuralnet(G_output, aux_nn)\r\n","    \r\n","    return loss, accuracy\r\n","\r\n","def run_test(x, y):\r\n","    output, _ = forward_neuralnet(x)\r\n","    accuracy = eval_accuracy(output, y)\r\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOVtMPCsB0rr"},"source":["### 단층 퍼셉트론에 대한 순전파 및 역전파 함수 정의"]},{"cell_type":"code","metadata":{"id":"FqJqsFjSoN-W"},"source":["def forward_neuralnet(x):\r\n","    global weight, bias\r\n","    output = np.matmul(x, weight) + bias\r\n","    return output, x\r\n","\r\n","def backprop_neuralnet(G_output, x):\r\n","    global weight, bias\r\n","    g_output_w = x.transpose()\r\n","    \r\n","    G_w = np.matmul(g_output_w, G_output)\r\n","    G_b = np.sum(G_output, axis=0)\r\n","\r\n","    weight -= LEARNING_RATE * G_w\r\n","    bias -= LEARNING_RATE * G_b"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"juSrTzReB6jK"},"source":["### 후처리 과정에 대한 순전파 및 역전파 함수 정의"]},{"cell_type":"code","metadata":{"id":"mQQD7WYKoPdj"},"source":["def forward_postproc(output, y):\r\n","    entropy = softmax_cross_entropy_with_logits(y, output)\r\n","    loss = np.mean(entropy) \r\n","    return loss, [y, output, entropy]\r\n","\r\n","def backprop_postproc(G_loss, aux):\r\n","    y, output, entropy = aux\r\n","    \r\n","    g_loss_entropy = 1.0 / np.prod(entropy.shape)\r\n","    g_entropy_output = softmax_cross_entropy_with_logits_derv(y, output)\r\n","    \r\n","    G_entropy = g_loss_entropy * G_loss\r\n","    G_output = g_entropy_output * G_entropy\r\n","    \r\n","    return G_output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YpHvY2KydPQA"},"source":["### 정확도 계산 함수의 재정의"]},{"cell_type":"code","metadata":{"id":"Y7HAuKPqdR8T"},"source":["def eval_accuracy(output, y):\r\n","    estimate = np.argmax(output, axis=1)\r\n","    answer = np.argmax(y, axis=1)\r\n","    correct = np.equal(estimate, answer)\r\n","    \r\n","    return np.mean(correct)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U70jIlsfc0qS"},"source":["### 소프트맥스 관련 함수 정의"]},{"cell_type":"code","metadata":{"id":"1iH-idxcdFQv"},"source":["def softmax(x):\r\n","    max_elem = np.max(x, axis=1)\r\n","    diff = (x.transpose() - max_elem).transpose()\r\n","    exp = np.exp(diff)\r\n","    sum_exp = np.sum(exp, axis=1)\r\n","    probs = (exp.transpose() / sum_exp).transpose()\r\n","    return probs\r\n","\r\n","def softmax_derv(x, y):\r\n","    mb_size, nom_size = x.shape\r\n","    derv = np.ndarray([mb_size, nom_size, nom_size])\r\n","    for n in range(mb_size):\r\n","        for i in range(nom_size):\r\n","            for j in range(nom_size):\r\n","                derv[n, i, j] = -y[n,i] * y[n,j]\r\n","            derv[n, i, i] += y[n,i]\r\n","    return derv\r\n","\r\n","def softmax_cross_entropy_with_logits(labels, logits):\r\n","    probs = softmax(logits)\r\n","    return -np.sum(labels * np.log(probs+1.0e-10), axis=1)\r\n","\r\n","def softmax_cross_entropy_with_logits_derv(labels, logits):\r\n","    return softmax(logits) - labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UBycARUDe_Dv"},"source":["## 실행하기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3JvatobfBbo","executionInfo":{"status":"ok","timestamp":1612080525837,"user_tz":-540,"elapsed":1312,"user":{"displayName":"Ho","photoUrl":"","userId":"04796031619100753677"}},"outputId":"2341e849-b2a9-4d36-d364-9a028c902914"},"source":["steel_exec()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1: loss=16.341, accuracy=0.290/0.228\n","Epoch 2: loss=15.851, accuracy=0.312/0.235\n","Epoch 3: loss=15.360, accuracy=0.333/0.184\n","Epoch 4: loss=15.464, accuracy=0.328/0.332\n","Epoch 5: loss=15.866, accuracy=0.311/0.238\n","Epoch 6: loss=15.524, accuracy=0.326/0.230\n","Epoch 7: loss=15.776, accuracy=0.315/0.343\n","Epoch 8: loss=15.791, accuracy=0.314/0.184\n","Epoch 9: loss=15.375, accuracy=0.332/0.384\n","Epoch 10: loss=15.346, accuracy=0.334/0.238\n","\n","Final Test: final accuracy = 0.238\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3dgicArfDOU","executionInfo":{"status":"ok","timestamp":1612080549837,"user_tz":-540,"elapsed":1228,"user":{"displayName":"Ho","photoUrl":"","userId":"04796031619100753677"}},"outputId":"6557be98-7e0a-4192-c34c-5492e20f7288"},"source":["LEARNING_RATE = 0.0001\r\n","steel_exec()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1: loss=16.103, accuracy=0.301/0.256\n","Epoch 2: loss=15.851, accuracy=0.312/0.458\n","Epoch 3: loss=15.687, accuracy=0.319/0.463\n","Epoch 4: loss=15.866, accuracy=0.311/0.248\n","Epoch 5: loss=15.613, accuracy=0.322/0.248\n","Epoch 6: loss=15.613, accuracy=0.322/0.169\n","Epoch 7: loss=15.732, accuracy=0.317/0.210\n","Epoch 8: loss=15.583, accuracy=0.323/0.361\n","Epoch 9: loss=15.301, accuracy=0.335/0.363\n","Epoch 10: loss=15.643, accuracy=0.321/0.381\n","\n","Final Test: final accuracy = 0.381\n"],"name":"stdout"}]}]}