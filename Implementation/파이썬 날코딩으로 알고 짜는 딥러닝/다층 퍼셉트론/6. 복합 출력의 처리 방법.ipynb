{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6. 복합 출력의 처리 방법.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMMuxLxidIlvrLtvtZLgAld"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"da3BjYn3uDHz"},"source":["# 6. 복합 출력의 처리 방법"]},{"cell_type":"markdown","metadata":{"id":"7A3Pk4RuuILE"},"source":["## 오피스31 데이터셋과 다차원 분류"]},{"cell_type":"markdown","metadata":{"id":"v0Qn6vNcvOBN"},"source":["**오피스31** 데이터는 컴퓨터 비전 분야에서의 전이학습 연구용으로 구축된 표준 벤치마크 데이터셋\r\n","> 전이학습이란, 한 도메인에서 학습한 결과를 다른 도메인에 활용하여 학습 효과를 높이는 학습 기법"]},{"cell_type":"markdown","metadata":{"id":"qdLzj709w8tO"},"source":["### 딥러닝에서의 복합 출력의 학습법"]},{"cell_type":"markdown","metadata":{"id":"klFDLd5n1Jdh"},"source":["동일한 신경망을 사용하더라도 순전파 후처리 과정, 역전파 후저리 과정만 변경하면 여러 데이터셋에 적용할 수 있다.  \r\n","> 순전파 후처리 과정은 손실 함수를 계산해 주고 역전파 후처리 과정은 손실 함수에 적합한 미분을 계산해 준다.\r\n","\r\n","복합 출력의 경우에도 후처리 과정을 달리하여 데이터셋을 적용할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"GqH7IKkP5lgD"},"source":["### 아담 알고리즘"]},{"cell_type":"markdown","metadata":{"id":"Y5Evz9_g5nKy"},"source":["아담 알고리즘은 경사하강법의 한 종류로 학습에 필요한 파라미터를 동적으로 조절해준다.  \r\n","\r\n","일반적인 경사하강법은 해당 파라미터의 손실 기울기와 학습률을 곱한 값을 각 파라미터에서 빼주는 방법으로 학습한다.  \r\n","\r\n","$$ \\theta := \\theta - \\alpha{\\frac{\\partial}{\\partial{\\theta}}}cost(\\theta)$$\r\n","$cost(\\theta)$ : 손실 함수  \r\n","$\\alpha$ : 학습률\r\n","\r\n","\r\n","아담 알고리즘의 경우 모멘텀의 개념을 도입해 처리 과정을 보완했다.\r\n","> 모멘텀이란, 주로 관성력으로 번역되지만 최근에는 파라미터값의 변화 추세를 나타내는 정보로서 표현한다.\r\n","\r\n","이 알고리즘의 경우 일반적인 경사하강법에 모멘텀과 2차 모멘텀 정보를 활용하여 값을 계산한다. 이때 모델에 속한 파라미터 각각 마다 모멘텀과 2차 모멘텀의 정보가 사용돼 메모리 소비량이 이전보다 많아진다. 하지만, 여러 정보를 이용함으로써 일괄적인 학습률 적용에서 오는 품질 저하를 막아준다.\r\n"]}]}