{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PASCAL VOC 2007(Object Detection).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2XcArP6DWO9bqC+r42f+J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNKwCS6MFdt3","executionInfo":{"status":"ok","timestamp":1618983854392,"user_tz":-540,"elapsed":23024,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"bae6a4e8-0476-4ad8-a696-e17b126eb9a3"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C06VKAAIF_jN","executionInfo":{"status":"ok","timestamp":1618984119973,"user_tz":-540,"elapsed":695,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"a98ef594-d89a-4c7f-fd03-fcc23cf711e7"},"source":["%cd '/content/gdrive/MyDrive/PASCAL/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/PASCAL\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vHvWz5-oEiXV"},"source":["!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n","!wget http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbsqCtDrM7qL"},"source":["!tar -xvf VOCtrainval_06-Nov-2007.tar\n","!tar -xvf VOCtest_06-Nov-2007.tar"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xvTG8k0Co9Jn"},"source":["PASCAL VOC 2007 directory\n","```\n","/VOCdevkit//VOC2007/\n","├── Annotations        \n","│   └── *.xml\n","├── ImageSets\n","│   ├── Layout\n","│   │   └── *.txt\n","│   ├── Main\n","│   │   └── *.txt\n","│   └── Segmentation\n","│        └── *.txt\n","├── JPEGImages\n","│   └── .jpg\n","├── SegmentationClass\n","│   └── *.png\n","└── SegmentationObject\n","     └── *.png\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"VRoMmOZMZzRp"},"source":["ImageSets\n","- class 별 train/val/test txt 파일\n","- object와 class 일치 여부(일치 : 1, 불일치 : -1) \n","\n","Annotations\n","```\n","<object>\n","    <name>dog</name>                # object class\n","    <pose>Left</pose>               # object의 방향 \n","    <truncated>1</truncated>        # object 잘림 여부\n","    <difficult>0</difficult>        # object 인식 난이도\n","    <bndbox>                        # object bounding box\n","        <xmin>48</xmin>             # bounding box 좌상단 x 좌표\n","        <ymin>240</ymin>            # bounding box 좌상단 y 좌표\n","        <xmax>195</xmax>            # bounding box 우하단 x 좌표 \n","        <ymax>371</ymax>            # bounding box 우하단 y 좌표 \n","    </bndbox>\n","</object>\n","```\n","\n","참조 : [PASCAL VOC 2007 데이터셋 다운로드 및 확인 방법](https://ndb796.tistory.com/500)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_8b3dIAarE2","executionInfo":{"status":"ok","timestamp":1617968428231,"user_tz":-540,"elapsed":2063,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"22b35e62-ff0a-4b6c-ab00-77c8cfaf434a"},"source":["!cat './VOCdevkit/VOC2007/Annotations/000001.xml'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<annotation>\n","\t<folder>VOC2007</folder>\n","\t<filename>000001.jpg</filename>\n","\t<source>\n","\t\t<database>The VOC2007 Database</database>\n","\t\t<annotation>PASCAL VOC2007</annotation>\n","\t\t<image>flickr</image>\n","\t\t<flickrid>341012865</flickrid>\n","\t</source>\n","\t<owner>\n","\t\t<flickrid>Fried Camels</flickrid>\n","\t\t<name>Jinky the Fruit Bat</name>\n","\t</owner>\n","\t<size>\n","\t\t<width>353</width>\n","\t\t<height>500</height>\n","\t\t<depth>3</depth>\n","\t</size>\n","\t<segmented>0</segmented>\n","\t<object>\n","\t\t<name>dog</name>\n","\t\t<pose>Left</pose>\n","\t\t<truncated>1</truncated>\n","\t\t<difficult>0</difficult>\n","\t\t<bndbox>\n","\t\t\t<xmin>48</xmin>\n","\t\t\t<ymin>240</ymin>\n","\t\t\t<xmax>195</xmax>\n","\t\t\t<ymax>371</ymax>\n","\t\t</bndbox>\n","\t</object>\n","\t<object>\n","\t\t<name>person</name>\n","\t\t<pose>Left</pose>\n","\t\t<truncated>1</truncated>\n","\t\t<difficult>0</difficult>\n","\t\t<bndbox>\n","\t\t\t<xmin>8</xmin>\n","\t\t\t<ymin>12</ymin>\n","\t\t\t<xmax>352</xmax>\n","\t\t\t<ymax>498</ymax>\n","\t\t</bndbox>\n","\t</object>\n","</annotation>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R27l_biPWwK1"},"source":["import os\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MG5jG_LuHHp4"},"source":["def extract_file(imageset_path, file_type, class_name=\"\"):\n","    if class_name != \"\":\n","        class_name += '_'\n","    file_path = imageset_path + class_name + file_type + '.txt'\n","\n","    cls = []\n","\n","    with open(file_path, 'r') as f:\n","        reader = f.readlines()\n","        for line in reader:\n","            check = line.strip().split(' ')\n","            if class_name != \"\":\n","               if check[-1] == str(1):\n","                   cls.append(check[0])\n","            else:           \n","                cls.append(check[0])\n","    return np.array(cls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Km2wIs_kR5oL"},"source":["classes = set()\n","dir_name = './VOCdevkit/VOC2007/'\n","\n","imageset = 'ImageSets/Main/'\n","imageset_path = os.path.join(dir_name, imageset)\n","\n","annotation = 'Annotations/'\n","annotation_path = os.path.join(dir_name, annotation)\n","\n","jpeg = 'JPEGImages/'\n","jpeg_path = os.path.join(dir_name, jpeg)\n","\n","class_dir = os.listdir(imageset_path)\n","annot_dir = os.listdir(annotation_path)\n","jpeg_dir = os.listdir(jpeg_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrwKVx3kCuKm","executionInfo":{"status":"ok","timestamp":1618985332355,"user_tz":-540,"elapsed":666,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"a6b01c1f-4975-4192-c25c-8a03a290cad3"},"source":["for cls in class_dir:\n","    cls = cls.split('/')[-1].split('_')[0]\n","    if '.txt' not in cls:\n","        classes.add(cls)\n","\n","print(len(classes), classes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20 {'boat', 'cow', 'motorbike', 'pottedplant', 'dog', 'car', 'tvmonitor', 'person', 'chair', 'aeroplane', 'bus', 'bicycle', 'bird', 'cat', 'bottle', 'horse', 'sheep', 'sofa', 'diningtable', 'train'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yd-LnPYr_Bkz"},"source":["samples = {\n","    'train': extract_file(imageset_path, 'train'),\n","    'validation': extract_file(imageset_path, 'val'),\n","    'test': extract_file(imageset_path, 'test')\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ffJ0urzgcGtH","executionInfo":{"status":"ok","timestamp":1618985525367,"user_tz":-540,"elapsed":5015,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"8949477a-40ff-4b9b-9ab2-1897215557ae"},"source":["!pip install xmltodict"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting xmltodict\n","  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n","Installing collected packages: xmltodict\n","Successfully installed xmltodict-0.12.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y-_fy7JUEfCS"},"source":["col_names = ['file_name', 'file_type', 'object_length', 'object', 'xmin', 'ymin', 'xmax', 'ymax', 'pose', 'truncated', 'difficult']\n","df_dict = {col_name : [] for col_name in col_names}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9awSbodtTCP9","executionInfo":{"status":"ok","timestamp":1618989592981,"user_tz":-540,"elapsed":561,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"870b52cb-e636-4f2f-c08b-69264da26569"},"source":["for obj in value['annotation']['object']:\n","    print(obj)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["OrderedDict([('name', 'person'), ('pose', 'Left'), ('truncated', '0'), ('difficult', '0'), ('bndbox', OrderedDict([('xmin', '185'), ('ymin', '62'), ('xmax', '279'), ('ymax', '199')]))])\n","OrderedDict([('name', 'horse'), ('pose', 'Left'), ('truncated', '0'), ('difficult', '0'), ('bndbox', OrderedDict([('xmin', '90'), ('ymin', '78'), ('xmax', '403'), ('ymax', '336')]))])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0vX7R2Aja-Hh"},"source":["import xmltodict\n","\n","def parse_xml(annotation_path, file_name, file_type):\n","    global df_dict\n","    xml_name = file_name + '.xml'\n","    xml_path = os.path.join(annotation_path, xml_name)\n","\n","    with open(xml_path, 'rb') as f:\n","        xml_dict = xmltodict.parse(f)\n","\n","        objects = xml_dict['annotation']['object']\n","\n","        if isinstance(objects, list):\n","            for obj in objects:\n","                df_dict['file_name'].append(xml_dict['annotation']['filename'])\n","                df_dict['file_type'].append(file_type)\n","                df_dict['object_length'].append(len(objects))\n","                df_dict['object'].append(obj['name'])\n","\n","                bndbox = obj['bndbox']\n","                df_dict['xmin'].append(int(bndbox['xmin']))\n","                df_dict['ymin'].append(int(bndbox['ymin']))\n","                df_dict['xmax'].append(int(bndbox['xmax']))\n","                df_dict['ymax'].append(int(bndbox['ymax']))\n","                df_dict['pose'].append(obj['pose'])\n","                df_dict['truncated'].append(int(obj['truncated']))\n","                df_dict['difficult'].append(int(obj['difficult']))\n","\n","        elif isinstance(objects, dict):\n","            df_dict['file_name'].append(xml_dict['annotation']['filename'])\n","            df_dict['file_type'].append(file_type)\n","            df_dict['object_length'].append(len(objects))\n","            df_dict['object'].append(objects['name'])\n","\n","            bndbox = objects['bndbox']\n","            df_dict['xmin'].append(int(bndbox['xmin']))\n","            df_dict['ymin'].append(int(bndbox['ymin']))\n","            df_dict['xmax'].append(int(bndbox['xmax']))\n","            df_dict['ymax'].append(int(bndbox['ymax']))\n","            df_dict['pose'].append(objects['pose'])\n","            df_dict['truncated'].append(int(objects['truncated']))\n","            df_dict['difficult'].append(int(objects['difficult']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kn9q1xxeexas"},"source":["for file_name in samples['train']:\n","    parse_xml(annotation_path, file_name, 'train')\n","\n","for file_name in samples['test']:\n","    parse_xml(annotation_path, file_name, 'test')\n","\n","for file_name in samples['validation']:\n","    parse_xml(annotation_path, file_name, 'validation')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2vCkEB4exau"},"source":["with open('dataframe_dict.pickle','wb') as fw:\n","    pickle.dump(df_dict, fw)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JG9gdzDJg3a2"},"source":["with open('dataframe_dict.pickle', 'rb') as fr:\n","    dataframe_dict = pickle.load(fr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMN_GCpZYJiI"},"source":["df = pd.DataFrame.from_dict(dataframe_dict)\n","df.to_csv('df.csv', index=False)"],"execution_count":null,"outputs":[]}]}