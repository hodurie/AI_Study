{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FCN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNSonT1d3xVYYZhdWbr/RmG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ssuOJ12Y1PC-","executionInfo":{"status":"ok","timestamp":1619435566694,"user_tz":-540,"elapsed":4362,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.optim as optim\n","from torchvision import models\n","from torchvision.models.vgg import VGG\n","\n","\n","import numpy as np \n","import time\n","\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"kn5GlPR4_xRS"},"source":["vgg16 = models.vgg16(pretrained=True)\n","vgg16_bn = models.vgg16_bn(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxveAF-w6siI","executionInfo":{"status":"ok","timestamp":1619440397628,"user_tz":-540,"elapsed":1422,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class FCN32s(nn.Module):\n","    def __init__(self, model, num_classes):\n","        super(FCN32s, self).__init__()\n","        self.num_classes = num_classes\n","        self.model = model\n","        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.classifier = nn.Conv2d(32, num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        x5 = output['x5']\n","\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv1(x5), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv2(score), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv3(score), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv4(score), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv5(score), inplace=True))\n","        score = self.classifier(score)\n","\n","        return score        "],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"gv2-F8wm7ZRD","executionInfo":{"status":"ok","timestamp":1619440395743,"user_tz":-540,"elapsed":932,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class FCN16s(nn.Module):\n","    def __init__(self, model, num_classes):\n","        super(FCN16s, self).__init__()\n","        self.num_classes = num_classes\n","        self.model = model\n","        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.classifier = nn.Conv2d(32, num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        x5 = output['x5']\n","        x4 = output['x4']\n","\n","        score = nn.ReLU(self.deconv1(x5), inplace=True)\n","        score = nn.BatchNorm2d(score + x4)\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv2(score), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv3(score), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv4(score), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv5(score), inplace=True))\n","        score = self.classifier(score)\n","\n","        return score        "],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9D2NPnh7aFc","executionInfo":{"status":"ok","timestamp":1619440394588,"user_tz":-540,"elapsed":926,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}}},"source":["class FCN8s(nn.Module):\n","    def __init__(self, model, num_classes):\n","        super(FCN8s, self).__init__()\n","        self.num_classes = num_classes\n","        self.model = model\n","        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.classifier = nn.Conv2d(32, num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        x5 = output['x5']\n","        x4 = output['x4']\n","        x3 = output['x3']\n","\n","        score = nn.ReLU(self.deconv1(x5), inplace=True)\n","        score = nn.BatchNorm2d(score + x4)\n","        score = nn.ReLU(self.deconv2(x4), inplace=True)\n","        score = nn.BatchNorm2d(score + x3)\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv3(score), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv4(score), inplace=True))\n","        score = nn.BatchNorm2d(nn.ReLU(self.deconv5(score), inplace=True))\n","        score = self.classifier(score)\n","\n","        return score        "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"DCwt_Gtm53fc"},"source":["class FCN(nn.Module):\n","    def __init__(self):\n","        super(FCN, self)).__init__()\n","        \n","    def forward(self, x):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pM8vjx7B63jK"},"source":["class VGGNet(nn.Module):\n","    def __init__(self, cfg, batch_norm):\n","        super(VGGNet, self).__init__()\n","\n","    def _make_layers(self, cfg, batch_norm=False):\n","        layers = []\n","        for v in cfg:\n","            if v == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","                if batch_norm:\n","                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","                else:\n","                    layers += [conv2d, nn.ReLU(inplace=True)]\n","                in_channels = v\n","\n","        return nn.Sequential(*layers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8RafPSSAyDN","executionInfo":{"status":"ok","timestamp":1619438020295,"user_tz":-540,"elapsed":1017,"user":{"displayName":"SH","photoUrl":"","userId":"04796031619100753677"}},"outputId":"98a49471-2ee0-405d-e045-dfb3e56ce146"},"source":["vgg16.load_state_dict"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.load_state_dict of VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"NQlJAcc509vu"},"source":["## Reference\n","- [Fully Convolutional Networks for Semantic Segmentation](https://gaussian37.github.io/vision-segmentation-fcn/)"]}]}